{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "from numpy import mean\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from util.parse import generate_dictionaries, generate_id_dict, encode_triples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from config import FB15K\n",
    "\n",
    "dataset = \"FB15K\"\n",
    "\n",
    "with open(FB15K().PARSED_MODELS_PATH, 'r') as file:\n",
    "    fb15k_models = json.load(file)\n",
    "\n",
    "# models = armstrader_models if dataset.identifier == \"armstrader\" else vcslam_models\n",
    "models = fb15k_models\n",
    "template = fb15k_models\n",
    "triples = []\n",
    "for model in models[:]:\n",
    "    for triple in model:\n",
    "        triples.append(tuple(triple))\n",
    "\n",
    "classes, predicates = generate_dictionaries(triples)\n",
    "classes_mapping = generate_id_dict(classes)\n",
    "predicates_mapping = generate_id_dict(predicates)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "272115"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# triples = modrel.reduce_relations(triples, targets)\n",
    "\n",
    "#test_triples = random.sample(triples, floor(len(triples) / 10))\n",
    "# test_triples = [triple for triple in test_triples if triple[0] == 'http://schema.org/Offer' and triple[2] == str(XSD.string)]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "limit = 20000\n",
    "test = 2000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Statistics Recommender Baseline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from modelextension.statistics_recommender import StatisticsRecommender as SR\n",
    "from util.metrics import calc_hits_mrr\n",
    "from util.utilities import prepare_data\n",
    "\n",
    "X, y = prepare_data(template, c_map=classes_mapping,\n",
    "                    p_map=predicates_mapping, shuffle=False, multiply=1)\n",
    "\n",
    "encoded_triples = encode_triples(triples, classes_mapping, predicates_mapping)\n",
    "sr = SR(triples=encoded_triples[:limit-test])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR FB15K MRR 0.9505958333333334, Hits@1 0.9048, Hits@3 0.99845\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = sr.predict_links(X[test:limit])\n",
    "hits_mrr = calc_hits_mrr( pred, y[test:limit])\n",
    "print(f'SR {dataset} MRR {hits_mrr[\"mrr\"]}, Hits@1 {hits_mrr[\"hits@1\"]}, Hits@3 {hits_mrr[\"hits@3\"]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train RFC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "%%capture\n",
    "from util.metrics import calc_hits_mrr\n",
    "from util.utilities import prepare_data\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "\n",
    "X, y = prepare_data(models = template, multiply=1, c_map=classes_mapping,\n",
    "                    p_map=predicates_mapping)\n",
    "rfc = RandomForestClassifier(n_estimators=10, max_depth=20)\n",
    "rfc_results = cross_validate(rfc, X[:], y[:].reshape(-1), scoring='accuracy', cv=cv, n_jobs=-1,\n",
    "                             error_score='raise', return_estimator=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC FB15K 10 20 | 0.590 0.483 0.643\n"
     ]
    }
   ],
   "source": [
    "mrrs = []\n",
    "hits_1 = []\n",
    "hits_3 = []\n",
    "for est in rfc_results['estimator']:\n",
    "    pred = est.predict_proba(X[:limit])\n",
    "    hits_mrr = calc_hits_mrr(pred, y)\n",
    "    hits_1.append(hits_mrr['hits@1'])\n",
    "    hits_3.append(hits_mrr['hits@3'])\n",
    "    mrrs.append(hits_mrr['mrr'])\n",
    "\n",
    "print(f'RFC {dataset} 10 20 | {mean(mrrs):.3f} {mean(hits_1):.3f} {mean(hits_3):.3f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train RGCN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training triples size 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\repo\\semantic_recommender\\linkprediction\\utils.py:127: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  norm = 1.0 / in_deg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 MRR 0.00 hits@1 0.00 hits@3 0.00*** | epoch 200 MRR 0.00 hits@1 0.00 hits@3 0.00*** | epoch 300 MRR 0.00 hits@1 0.00 hits@3 0.00*** | epoch 400 MRR 0.00 hits@1 0.00 hits@3 0.00*** | epoch 500 MRR 0.00 hits@1 0.00 hits@3 0.00*** | epoch 600 MRR 0.01 hits@1 0.00 hits@3 0.01*** | epoch 700 MRR 0.01 hits@1 0.01 hits@3 0.02*** | epoch 800 MRR 0.01 hits@1 0.01 hits@3 0.01*** | epoch 900 MRR 0.02 hits@1 0.01 hits@3 0.02*** | epoch 1000 MRR 0.03 hits@1 0.02 hits@3 0.03*** | epoch 1100 MRR 0.03 hits@1 0.02 hits@3 0.03*** | epoch 1200 MRR 0.03 hits@1 0.02 hits@3 0.03*** | epoch 1300 MRR 0.04 hits@1 0.03 hits@3 0.04*** | epoch 1400 MRR 0.04 hits@1 0.03 hits@3 0.04*** | epoch 1500 MRR 0.04 hits@1 0.03 hits@3 0.04*** | epoch 1600 MRR 0.04 hits@1 0.03 hits@3 0.05*** | epoch 1700 MRR 0.05 hits@1 0.04 hits@3 0.06*** | epoch 1800 MRR 0.05 hits@1 0.04 hits@3 0.05*** | epoch 1900 MRR 0.05 hits@1 0.04 hits@3 0.06*** | epoch 2000 MRR 0.05 hits@1 0.04 hits@3 0.05 | epoch 2100 MRR 0.05 hits@1 0.04 hits@3 0.05 | epoch 2200 MRR 0.05 hits@1 0.04 hits@3 0.06 | epoch 2300 MRR 0.06 hits@1 0.04 hits@3 0.06*** | epoch 2400 MRR 0.06 hits@1 0.05 hits@3 0.07*** | epoch 2500 MRR 0.06 hits@1 0.05 hits@3 0.07*** | epoch 2600 MRR 0.07 hits@1 0.05 hits@3 0.07*** | epoch 2700 MRR 0.06 hits@1 0.05 hits@3 0.07 | epoch 2800 MRR 0.06 hits@1 0.05 hits@3 0.07 | epoch 2900 MRR 0.07 hits@1 0.05 hits@3 0.07 | epoch 3000 MRR 0.07 hits@1 0.05 hits@3 0.07 | epoch 3100 MRR 0.07 hits@1 0.06 hits@3 0.08*** | epoch 3200 MRR 0.07 hits@1 0.06 hits@3 0.08 | epoch 3300 MRR 0.07 hits@1 0.05 hits@3 0.07 | epoch 3400 MRR 0.07 hits@1 0.06 hits@3 0.08 | epoch 3500 MRR 0.07 hits@1 0.05 hits@3 0.08 | epoch 3600 MRR 0.08 hits@1 0.06 hits@3 0.08*** | epoch 3700 MRR 0.08 hits@1 0.06 hits@3 0.08*** | epoch 3800 MRR 0.08 hits@1 0.06 hits@3 0.08 | epoch 3900 MRR 0.08 hits@1 0.06 hits@3 0.08 | epoch 4000 MRR 0.08 hits@1 0.06 hits@3 0.09*** | epoch 4100 MRR 0.08 hits@1 0.06 hits@3 0.09 | epoch 4200 MRR 0.08 hits@1 0.06 hits@3 0.09*** | epoch 4300 MRR 0.08 hits@1 0.06 hits@3 0.09 | epoch 4400 MRR 0.08 hits@1 0.06 hits@3 0.09 | epoch 4500 MRR 0.08 hits@1 0.06 hits@3 0.09 | epoch 4600 MRR 0.08 hits@1 0.06 hits@3 0.08 | epoch 4700 MRR 0.08 hits@1 0.06 hits@3 0.09 | epoch 4800 MRR 0.08 hits@1 0.06 hits@3 0.09 | epoch 4900 MRR 0.09 hits@1 0.06 hits@3 0.09*** | epoch 5000 MRR 0.09 hits@1 0.07 hits@3 0.09*** | "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from linkprediction import utils\n",
    "from linkprediction.rgcn import LinkPredict, node_norm_to_edge_norm\n",
    "\n",
    "train_triples = triples[:limit]\n",
    "test_triples = random.sample(triples[:limit], int(len(triples[:limit])/10))\n",
    "print(\"training triples size\", len(train_triples))\n",
    "\n",
    "train_data = encode_triples(train_triples, classes_mapping, predicates_mapping)\n",
    "valid_data = encode_triples(test_triples, classes_mapping, predicates_mapping)\n",
    "\n",
    "# load graph data\n",
    "num_nodes = len(classes)\n",
    "num_rels = len(predicates)\n",
    "\n",
    "# create model\n",
    "rgcn_model = LinkPredict(in_dim=num_nodes,\n",
    "                         h_dim=100,\n",
    "                         num_rels=num_rels,\n",
    "                         num_bases=10,\n",
    "                         num_hidden_layers=2,\n",
    "                         dropout=0.1,\n",
    "                         use_cuda=False,\n",
    "                         reg_param=0.01)\n",
    "\n",
    "# validation and testing triplets\n",
    "valid_data = torch.LongTensor(valid_data)\n",
    "test_data = torch.LongTensor(valid_data)\n",
    "\n",
    "# build test graph\n",
    "test_graph, test_rel, test_norm = utils.build_test_graph(\n",
    "    num_nodes, num_rels, train_data)\n",
    "test_deg = test_graph.in_degrees(\n",
    "    range(test_graph.number_of_nodes())).float().view(-1, 1)\n",
    "test_node_id = torch.arange(0, num_nodes, dtype=torch.long).view(-1, 1)\n",
    "test_rel = torch.from_numpy(test_rel)\n",
    "test_norm = node_norm_to_edge_norm(test_graph, torch.from_numpy(test_norm).view(-1, 1))\n",
    "\n",
    "# build adj list and calculate degrees for sampling\n",
    "adj_list, degrees = utils.get_adj_and_degrees(num_nodes, train_data)\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(rgcn_model.parameters(), lr=0.001)\n",
    "\n",
    "forward_time = []\n",
    "backward_time = []\n",
    "\n",
    "# training loop\n",
    "# print(\"start training...\")\n",
    "\n",
    "epoch = 0\n",
    "best_mrr = 0\n",
    "best_hits3 = 0\n",
    "checkpoint = None\n",
    "while True:\n",
    "    rgcn_model.train()\n",
    "    epoch += 1\n",
    "\n",
    "    # perform edge neighborhood sampling to generate training graph and data\n",
    "    g, node_id, edge_type, node_norm, data, labels = \\\n",
    "        utils.generate_sampled_graph_and_labels(\n",
    "            train_data, 20, 0.3,\n",
    "            num_rels, adj_list, degrees, 5,\n",
    "            \"neighbor\")\n",
    "    # print(\"Done edge sampling\")\n",
    "\n",
    "    # set node/edge feature\n",
    "    node_id = torch.from_numpy(node_id).view(-1, 1).long()\n",
    "    edge_type = torch.from_numpy(edge_type)\n",
    "    edge_norm = node_norm_to_edge_norm(g, torch.from_numpy(node_norm).view(-1, 1))\n",
    "    data, labels = torch.from_numpy(data), torch.from_numpy(labels)\n",
    "    deg = g.in_degrees(range(g.number_of_nodes())).float().view(-1, 1)\n",
    "\n",
    "    embed = rgcn_model(g, node_id, edge_type, edge_norm)\n",
    "    loss = rgcn_model.get_loss(g, embed, data, labels)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(rgcn_model.parameters(), 1.0)  # clip gradients\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # validation\n",
    "    if epoch % 100 == 0:\n",
    "        rgcn_model.eval()\n",
    "        # print(\"start eval\")\n",
    "        embed = rgcn_model(test_graph, test_node_id, test_rel, test_norm)\n",
    "        results = utils.calc_mrr(embed, rgcn_model.w_relation, torch.LongTensor(train_data),\n",
    "                                 valid_data, test_data, hits=[1, 3], eval_bz=100,\n",
    "                                 eval_p=\"filtered\")\n",
    "        mrr = results['mrr']\n",
    "        hits3 = results['hits@3']\n",
    "        hits1 = results['hits@1']\n",
    "        print(f\"epoch {epoch} MRR {mrr:.2f} hits@1 {hits1:.2f} hits@3 {hits3:.2f}\", end=\"\")\n",
    "        if best_hits3 < hits3:\n",
    "            best_hits3 = hits3\n",
    "        if best_mrr <= mrr:\n",
    "            best_mrr = mrr\n",
    "            checkpoint = {'state_dict': rgcn_model.state_dict(), 'epoch': epoch}\n",
    "            print(f\"*** | \", end=\"\")\n",
    "\n",
    "        else:\n",
    "            print(f\" | \", end=\"\")\n",
    "        # if hits3 == 1:\n",
    "        #    break\n",
    "\n",
    "        if epoch >= 5000:\n",
    "            break\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using best epoch: 5000\n",
      "RGCN FB15K MRR 0.08570608496665955 hits@1 0.06575000286102295 hits@3 0.09000000357627869\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# use best model checkpoint\n",
    "print(\"Using best epoch: {}\".format(checkpoint['epoch']))\n",
    "rgcn_model.eval()\n",
    "rgcn_model.load_state_dict(checkpoint['state_dict'])\n",
    "rgcn_embed = rgcn_model(test_graph, test_node_id, test_rel, test_norm)\n",
    "rgcn_results = utils.calc_mrr(rgcn_embed, rgcn_model.w_relation, torch.LongTensor(train_data), valid_data[:limit],\n",
    "                         test_data[:limit], hits=[1, 3], eval_bz=100, eval_p=\"filtered\")\n",
    "mrr = rgcn_results['mrr']\n",
    "hits3 = rgcn_results['hits@3']\n",
    "hits1 = rgcn_results['hits@1']\n",
    "print(f\"RGCN {dataset} MRR {mrr} hits@1 {hits1} hits@3 {hits3}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}