{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super(MLP, self).__init__()\n",
    "        self.d_in = d_in\n",
    "\n",
    "        self.linear1 = nn.Linear(d_in, 1024)\n",
    "        self.linear2 = nn.Linear(1024, 256)\n",
    "        self.linear3 = nn.Linear(256,64)\n",
    "        self.linear4 = nn.Linear(64,32)\n",
    "        self.linear5 = nn.Linear(32, d_out)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, self.d_in)\n",
    "        X = self.linear1(X)\n",
    "        X = self.linear2(X)\n",
    "        X = self.linear3(X)\n",
    "        X = self.linear4(X)\n",
    "        return F.relu(self.linear5(X))\n",
    "\n",
    "# input numpy arrays: \tin_vectors_train, out_vectors_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of models 101\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from config import Environment as env, VCSLAM\n",
    "\n",
    "model = VCSLAM()\n",
    "with open(model.PARSED_MODELS_PATH, 'r') as file:\n",
    "    models = json.load(file)\n",
    "\n",
    "print('# of models', len(models))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{'http://tmdtkg#agent': ['http://tmdtkg#ticket', 'http://tmdtkg#business'],\n 'http://tmdtkg#geoposition': ['http://tmdtkg#latitude',\n  'http://tmdtkg#longitude']}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocess.steiner_tree import get_mapped_attributes, get_anchored_target_nodes\n",
    "\n",
    "index = 1\n",
    "mod = models[index]\n",
    "mapped_nodes = get_mapped_attributes(index=index,model=model)\n",
    "anchored_nodes = get_anchored_target_nodes(mod,mapped_nodes)\n",
    "anchored_nodes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 08:51:59,301 [INFO] - PRE 10 triples\n",
      "(('http://schema.org/Offer', 'http://schema.org/name', 'http://www.w3.org/2001/XMLSchema#string'), 18330)\n",
      "(('http://schema.org/Offer', 'http://schema.org/price', 'http://www.w3.org/2001/XMLSchema#string'), 16230)\n",
      "(('http://schema.org/CreativeWork', 'http://schema.org/name', 'http://www.w3.org/2001/XMLSchema#string'), 12255)\n",
      "(('http://schema.org/Offer', 'http://schema.org/availableAtOrFrom', 'http://schema.org/Place'), 11253)\n",
      "(('http://schema.org/Offer', 'http://schema.org/description', 'http://www.w3.org/2001/XMLSchema#string'), 11190)\n",
      "(('http://schema.org/CreativeWork', 'http://schema.org/copyrightYear', 'http://www.w3.org/2001/XMLSchema#string'), 10845)\n",
      "(('http://schema.org/Offer', 'http://schema.org/mainEntityOfPage', 'http://schema.org/CreativeWork'), 10353)\n",
      "(('http://schema.org/Offer', 'http://schema.org/seller', 'http://schema.dig.isi.edu/ontology/PersonOrOrganization'), 8616)\n",
      "(('http://schema.org/Offer', 'http://schema.dig.isi.edu/ontology/identifier', 'http://www.w3.org/2001/XMLSchema#string'), 7335)\n",
      "(('http://schema.org/Place', 'http://schema.org/name', 'http://www.w3.org/2001/XMLSchema#string'), 6930)\n",
      "2022-05-02 08:51:59,390 [INFO] - POST 10 triples\n",
      "(('http://schema.org/Offer', 'http://schema.org/name', 'http://www.w3.org/2001/XMLSchema#string'), 14644)\n",
      "(('http://schema.org/CreativeWork', 'http://schema.org/name', 'http://www.w3.org/2001/XMLSchema#string'), 12255)\n",
      "(('http://schema.org/Offer', 'http://schema.org/description', 'http://www.w3.org/2001/XMLSchema#string'), 11190)\n",
      "(('http://schema.org/CreativeWork', 'http://schema.org/copyrightYear', 'http://www.w3.org/2001/XMLSchema#string'), 10845)\n",
      "(('http://schema.org/Offer', 'http://schema.org/mainEntityOfPage', 'http://schema.org/CreativeWork'), 10353)\n",
      "(('http://schema.org/Offer', 'http://schema.org/seller', 'http://schema.dig.isi.edu/ontology/PersonOrOrganization'), 8616)\n",
      "(('http://schema.org/Offer', 'http://schema.org/availableAtOrFrom', 'http://schema.org/Place'), 7743)\n",
      "(('http://schema.org/Offer', 'http://schema.dig.isi.edu/ontology/identifier', 'http://www.w3.org/2001/XMLSchema#string'), 7335)\n",
      "(('http://schema.org/Place', 'http://schema.org/name', 'http://www.w3.org/2001/XMLSchema#string'), 6930)\n",
      "(('http://schema.dig.isi.edu/ontology/PersonOrOrganization', 'http://schema.dig.isi.edu/ontology/identifier', 'http://www.w3.org/2001/XMLSchema#string'), 6810)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training triples size 148886\n",
      "Train data size:  (148886, 3)\n",
      "Valid data size:  (14888, 3)\n"
     ]
    }
   ],
   "source": [
    "from util.parse import generate_dictionaries, generate_id_dict, encode_triples\n",
    "from math import floor\n",
    "import random\n",
    "\n",
    "test_triples = random.sample(triples, floor(len(triples) / 10))\n",
    "\n",
    "classes, predicates = generate_dictionaries(triples)\n",
    "classes_mapping = generate_id_dict(classes)\n",
    "predicates_mapping = generate_id_dict(predicates)\n",
    "train_triples = triples\n",
    "\n",
    "\n",
    "print(\"training triples size\", len(train_triples))\n",
    "\n",
    "train_data = encode_triples(train_triples, classes_mapping, predicates_mapping)\n",
    "valid_data = encode_triples(test_triples, classes_mapping, predicates_mapping)\n",
    "\n",
    "if env.LOG_LEVEL >= 10:\n",
    "    print(\"Train data size: \", train_data.shape)\n",
    "    print(\"Valid data size: \", valid_data.shape)\n",
    "\n",
    "in_vectors_train = []\n",
    "out_vectors_train = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for s,p,o in train_data:\n",
    "    subject_v = torch.zeros(len(classes_mapping))\n",
    "    subject_v[s] = 1\n",
    "    object_v = torch.zeros(len(classes_mapping))\n",
    "    object_v[o] = 1\n",
    "    combined_v = torch.cat([subject_v,object_v])\n",
    "    in_vectors_train.append(combined_v)\n",
    "    relation_v = torch.zeros(len(classes_mapping))\n",
    "    relation_v[p] = 1\n",
    "    out_vectors_train.append(relation_v)\n",
    "\n",
    "\n",
    "D_in = in_vectors_train[0].shape[0]\n",
    "D_out = out_vectors_train[0].shape[0]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def model_loss_ce(m, data, dev):\n",
    "  losses = []\n",
    "  for s,p,o in data:\n",
    "      subject_v = torch.zeros(len(classes_mapping))\n",
    "      subject_v[s] = 1\n",
    "      object_v = torch.zeros(len(classes_mapping))\n",
    "      object_v[o] = 1\n",
    "      combined_v = torch.cat([subject_v,object_v])\n",
    "\n",
    "      out = m(combined_v.to(dev))\n",
    "      out = out.detach().cpu()\n",
    "      loss = nn.CrossEntropyLoss()(out.view(1,-1), torch.LongTensor([p]))\n",
    "      losses.append(loss.detach().numpy().flat[0])\n",
    "\n",
    "  return np.mean(losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.838979 2300.1545646190643\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model = MLP(D_in, D_out).to(torch.device(device))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    loss = -100\n",
    "    start = time.time()\n",
    "    for i in range(0, int(len(in_vectors_train))):\n",
    "        input_vector = in_vectors_train[i]\n",
    "        output_vector = out_vectors_train[i]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_vector)\n",
    "        loss = loss_function(output.view(1,-1), output_vector.nonzero().view(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(epoch, model_loss_ce(model,valid_data,device), time.time() - start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}