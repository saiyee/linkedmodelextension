{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "from config import VCSLAM\n",
    "from util.parse import generate_dictionaries, generate_id_dict, encode_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "vcslam = VCSLAM()\n",
    "dataset = vcslam\n",
    "with open(vcslam.PARSED_MODELS_PATH, 'r') as file:\n",
    "    vcslam_models = json.load(file)\n",
    "\n",
    "# models = armstrader_models if dataset.identifier == \"armstrader\" else vcslam_models\n",
    "models = vcslam_models\n",
    "template = vcslam_models\n",
    "triples = []\n",
    "for model in models[:]:\n",
    "    for triple in model:\n",
    "        triples.append(tuple(triple))\n",
    "\n",
    "classes, predicates = generate_dictionaries(triples)\n",
    "classes_mapping = generate_id_dict(classes)\n",
    "predicates_mapping = generate_id_dict(predicates)\n",
    "\n",
    "encoded_triples = encode_triples(triples, classes_mapping, predicates_mapping)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "2560"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "Computing transition probabilities:   0%|          | 0/468 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d8ed208bcde4a2f9619ddec6839758d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 17:48:33,106 [INFO] - collecting all words and their counts\n",
      "2022-10-28 17:48:33,107 [INFO] - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-10-28 17:48:33,126 [INFO] - collected 468 word types from a corpus of 140400 raw words and 4680 sentences\n",
      "2022-10-28 17:48:33,127 [INFO] - Creating a fresh vocabulary\n",
      "2022-10-28 17:48:33,129 [INFO] - Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 468 unique words (100.0%% of original 468, drops 0)', 'datetime': '2022-10-28T17:48:33.129650', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-10-28 17:48:33,129 [INFO] - Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 140400 word corpus (100.0%% of original 140400, drops 0)', 'datetime': '2022-10-28T17:48:33.129650', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-10-28 17:48:33,132 [INFO] - deleting the raw counts dictionary of 468 items\n",
      "2022-10-28 17:48:33,132 [INFO] - sample=0.001 downsamples 83 most-common words\n",
      "2022-10-28 17:48:33,133 [INFO] - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 111038.73844184313 word corpus (79.1%% of prior 140400)', 'datetime': '2022-10-28T17:48:33.133654', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-10-28 17:48:33,137 [INFO] - estimated required memory for 468 words and 100 dimensions: 608400 bytes\n",
      "2022-10-28 17:48:33,138 [INFO] - resetting layer weights\n",
      "2022-10-28 17:48:33,139 [INFO] - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-10-28T17:48:33.139652', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2022-10-28 17:48:33,139 [INFO] - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 468 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2022-10-28T17:48:33.139652', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-10-28 17:48:33,359 [INFO] - worker thread finished; awaiting finish of 3 more threads\n",
      "2022-10-28 17:48:33,361 [INFO] - worker thread finished; awaiting finish of 2 more threads\n",
      "2022-10-28 17:48:33,407 [INFO] - worker thread finished; awaiting finish of 1 more threads\n",
      "2022-10-28 17:48:33,409 [INFO] - worker thread finished; awaiting finish of 0 more threads\n",
      "2022-10-28 17:48:33,410 [INFO] - EPOCH - 1 : training on 140400 raw words (110988 effective words) took 0.3s, 420038 effective words/s\n",
      "2022-10-28 17:48:33,619 [INFO] - worker thread finished; awaiting finish of 3 more threads\n",
      "2022-10-28 17:48:33,622 [INFO] - worker thread finished; awaiting finish of 2 more threads\n",
      "2022-10-28 17:48:33,671 [INFO] - worker thread finished; awaiting finish of 1 more threads\n",
      "2022-10-28 17:48:33,672 [INFO] - worker thread finished; awaiting finish of 0 more threads\n",
      "2022-10-28 17:48:33,672 [INFO] - EPOCH - 2 : training on 140400 raw words (111098 effective words) took 0.3s, 432297 effective words/s\n",
      "2022-10-28 17:48:33,887 [INFO] - worker thread finished; awaiting finish of 3 more threads\n",
      "2022-10-28 17:48:33,889 [INFO] - worker thread finished; awaiting finish of 2 more threads\n",
      "2022-10-28 17:48:33,926 [INFO] - worker thread finished; awaiting finish of 1 more threads\n",
      "2022-10-28 17:48:33,935 [INFO] - worker thread finished; awaiting finish of 0 more threads\n",
      "2022-10-28 17:48:33,936 [INFO] - EPOCH - 3 : training on 140400 raw words (111127 effective words) took 0.3s, 429394 effective words/s\n",
      "2022-10-28 17:48:34,171 [INFO] - worker thread finished; awaiting finish of 3 more threads\n",
      "2022-10-28 17:48:34,176 [INFO] - worker thread finished; awaiting finish of 2 more threads\n",
      "2022-10-28 17:48:34,213 [INFO] - worker thread finished; awaiting finish of 1 more threads\n",
      "2022-10-28 17:48:34,214 [INFO] - worker thread finished; awaiting finish of 0 more threads\n",
      "2022-10-28 17:48:34,215 [INFO] - EPOCH - 4 : training on 140400 raw words (111076 effective words) took 0.3s, 403937 effective words/s\n",
      "2022-10-28 17:48:34,439 [INFO] - worker thread finished; awaiting finish of 3 more threads\n",
      "2022-10-28 17:48:34,443 [INFO] - worker thread finished; awaiting finish of 2 more threads\n",
      "2022-10-28 17:48:34,485 [INFO] - worker thread finished; awaiting finish of 1 more threads\n",
      "2022-10-28 17:48:34,489 [INFO] - worker thread finished; awaiting finish of 0 more threads\n",
      "2022-10-28 17:48:34,490 [INFO] - EPOCH - 5 : training on 140400 raw words (111089 effective words) took 0.3s, 409254 effective words/s\n",
      "2022-10-28 17:48:34,491 [INFO] - Word2Vec lifecycle event {'msg': 'training on 702000 raw words (555378 effective words) took 1.4s, 411158 effective words/s', 'datetime': '2022-10-28T17:48:34.491521', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-10-28 17:48:34,491 [INFO] - Word2Vec lifecycle event {'params': 'Word2Vec(vocab=468, vector_size=100, alpha=0.025)', 'datetime': '2022-10-28T17:48:34.491521', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# combine relations as described by Paulus et al.\n",
    "sums = {}\n",
    "weights = {}\n",
    "outgoing = {}\n",
    "\n",
    "for (s, a, t) in triples:\n",
    "    if not (s, a, t) in weights:\n",
    "        weights[(s, a, t)] = 0\n",
    "    weights[(s, a, t)] += 1\n",
    "    if not (s, t) in sums:\n",
    "        sums[(s, t)] = 0\n",
    "    if not s in outgoing:\n",
    "        outgoing[s] = 0\n",
    "    outgoing[s] += 1\n",
    "    sums[(s, t)] += 1\n",
    "\n",
    "#weights = dict(sorted(weights.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_sums = sorted(sums.items(), reverse=True, key=lambda x: x[1])\n",
    "# print(sorted_sums)\n",
    "\n",
    "total = sum([count for count in sums.values()])\n",
    "\n",
    "graph = nx.Graph()\n",
    "for (s, t), count in sums.items():\n",
    "    weight = sums[(s, t)] / outgoing[s]\n",
    "    graph.add_edge(str(s), str(t), weight=weight)\n",
    "\n",
    "model_based_node2vec = Node2Vec(graph,\n",
    "                                p=1,\n",
    "                                q=1,\n",
    "                                dimensions=100,\n",
    "                                walk_length=30,\n",
    "                                #num_walks=1000,\n",
    "                                num_walks=10,\n",
    "                                workers=4)\n",
    "# print(\"walks size\", len(model_based_node2vec.walks), model_based_node2vec.num_walks)\n",
    "\n",
    "n2v = model_based_node2vec.fit(window=10, sg=1, negative=5,\n",
    "                               ns_exponent=1.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "base_path = Path(vcslam.LABEL_MAPPINGS_PATH)\n",
    "mapping_files = list(base_path.glob('*'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "def get_mapped_attributes(mappings_path) -> set[str]:\n",
    "    with open(mappings_path, encoding='utf-8') as mappings_file:\n",
    "        mappings = json.load(mappings_file)\n",
    "\n",
    "    label_mappings= [x['conceptResource'] for x in mappings]\n",
    "    label_mappings = set([x.replace('http://www.plasma.uni-wuppertal.de/schema#', 'http://tmdtkg#') for x in label_mappings])\n",
    "    return label_mappings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "from networkx import minimum_spanning_tree\n",
    "from networkx.algorithms.approximation import steiner_tree\n",
    "\n",
    "def get_anchored_target_nodes(model: [], mapped_nodes: [], filter_target_nodes=True) -> dict[Any, list[Any]]:\n",
    "\n",
    "    graph = nx.MultiDiGraph()\n",
    "    for s, p, o in model:\n",
    "        graph.add_edge(s, o, relation=str(p))\n",
    "\n",
    "    minimal_tree = compute_steiner_tree(model, mapped_nodes)\n",
    "\n",
    "    all_nodes = set(graph.nodes)\n",
    "    tree_nodes = set(minimal_tree.nodes)\n",
    "    target_nodes = all_nodes.difference(tree_nodes)\n",
    "\n",
    "    anchored_nodes = {}\n",
    "    # find the anchor for each target node\n",
    "    for anchor in graph.nodes:\n",
    "        if filter_target_nodes and anchor in target_nodes:\n",
    "            continue\n",
    "        found_nodes = []\n",
    "        for target in target_nodes:\n",
    "            if graph.has_edge(anchor,target):\n",
    "                relation = graph.edges[anchor,target,0]\n",
    "                found_nodes.append((anchor,relation[\"relation\"],target))\n",
    "\n",
    "        if found_nodes:\n",
    "            anchored_nodes[anchor] = found_nodes\n",
    "\n",
    "    return anchored_nodes\n",
    "\n",
    "def compute_steiner_tree(model, mapped_nodes) -> nx.Graph:\n",
    "    graph = nx.Graph()\n",
    "    for s, p, o in model:\n",
    "        if s == o:\n",
    "            continue\n",
    "        graph.add_node(s)\n",
    "        graph.add_node(o)\n",
    "        graph.add_edge(s, o)\n",
    "\n",
    "    mst = minimum_spanning_tree(graph, algorithm='prim')\n",
    "    # visualize(mst)\n",
    "\n",
    "    minimal_tree = steiner_tree(mst, list(mapped_nodes))\n",
    "\n",
    "    return minimal_tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped model 0 as 0 target nodes are found\n",
      "Skipped model 45 as 0 target nodes are found\n",
      "Skipped model 47 as 0 target nodes are found\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from modelextension.statistics_recommender import StatisticsRecommender as SR\n",
    "\n",
    "sr = SR(triples=encoded_triples)\n",
    "\n",
    "setups = []\n",
    "\n",
    "for id, model in enumerate(models[:]):\n",
    "    mapped_attributes = get_mapped_attributes(mapping_files[id])\n",
    "    recommended_nodes_set = set()\n",
    "    anchored_target_nodes = get_anchored_target_nodes(model=model, mapped_nodes=mapped_attributes)\n",
    "    # s_tree = compute_steiner_tree(model, mapped_nodes=mapped_attributes)\n",
    "    if not anchored_target_nodes:\n",
    "        print(f\"Skipped model {id} as 0 target nodes are found\")\n",
    "        continue\n",
    "    # print(f\"Target ({id}) {len(anchored_target_nodes)} {anchored_target_nodes}\")\n",
    "\n",
    "    for anchor, target_nodes in anchored_target_nodes.items():\n",
    "        similar = n2v.wv.most_similar(positive=anchor, topn=5)\n",
    "\n",
    "        neighbors = [(concept, 1) for concept, id in classes_mapping.items() if np.amax(sr.predict_link(classes_mapping[anchor], classes_mapping[concept])) > 0]\n",
    "        # all = [(concept, 1) for concept, id in classes_mapping.items() ]\n",
    "        oracle = [(target_nodes[0][2], 1) ]\n",
    "        setups.append({\n",
    "            \"anchor\": anchor,\n",
    "            \"target\": target_nodes,\n",
    "            \"oracle\": oracle,\n",
    "            \"neighbors\": neighbors,\n",
    "            \"similar\": similar,\n",
    "            # \"all\": all\n",
    "        })\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "#setups"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "with open(\"modelextensions.json\",\"w\") as file:\n",
    "    json.dump(setups,fp=file, indent=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "128"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicates\n",
    "anchors = []\n",
    "setups2 = []\n",
    "for setup in setups:\n",
    "    if setup['anchor'] not in anchors:\n",
    "        anchors.append(setup['anchor'])\n",
    "        setups2.append(setup)\n",
    "\n",
    "setups = setups2\n",
    "len(setups)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "with open(\"modelextensions_single.json\",\"w\") as file:\n",
    "    json.dump(setups,fp=file, indent=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import numpy as np\n",
    "\n",
    "def identify_similar_match(setup):\n",
    "    for (ts,tp,to) in setup[\"target\"]:\n",
    "        for (so,_) in setup[\"similar\"]:\n",
    "            if so == to:\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "def identify_neighbor_match(setup):\n",
    "    for (ts,tp,to) in setup[\"target\"]:\n",
    "        for (so,_) in setup[\"neighbors\"]:\n",
    "            if so == to:\n",
    "                return 1\n",
    "    return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n        0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n        1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n        1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n        0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n        1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]])"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = [identify_similar_match(setup) for setup in setups]\n",
    "result = array(result)\n",
    "result.reshape((1,-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6796875"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(result)/ len(setups)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = [identify_neighbor_match(setup) for setup in setups]\n",
    "result = array(result)\n",
    "result.reshape((1,-1))\n",
    "\n",
    "np.sum(result)/ len(setups)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "87"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setups = [setup for setup in setups if identify_similar_match(setup) == 1]\n",
    "len(setups)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "with open(\"modelextensions_filtered.json\",\"w\") as file:\n",
    "    json.dump(setups,fp=file, indent=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}