{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "from numpy import mean\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from config import ARMSTRADER, VCSLAM\n",
    "from util.parse import generate_dictionaries, generate_id_dict, encode_triples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset = \"combined\"\n",
    "\n",
    "vcslam = VCSLAM()\n",
    "with open(vcslam.PARSED_MODELS_PATH, 'r') as file:\n",
    "    vcslam_models = json.load(file)\n",
    "\n",
    "armstrader = ARMSTRADER()\n",
    "with open(armstrader.PARSED_MODELS_PATH, 'r') as file:\n",
    "    armstrader_models = json.load(file)\n",
    "\n",
    "models = armstrader_models + vcslam_models\n",
    "vcslam_x3 = armstrader_models + vcslam_models + vcslam_models + vcslam_models\n",
    "triples = []\n",
    "for model in models[:]:\n",
    "    for triple in model:\n",
    "        triples.append(tuple(triple))\n",
    "\n",
    "classes, predicates = generate_dictionaries(triples)\n",
    "classes_mapping = generate_id_dict(classes)\n",
    "predicates_mapping = generate_id_dict(predicates)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "173265"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# triples = modrel.reduce_relations(triples, targets)\n",
    "\n",
    "#test_triples = random.sample(triples, floor(len(triples) / 10))\n",
    "# test_triples = [triple for triple in test_triples if triple[0] == 'http://schema.org/Offer' and triple[2] == str(XSD.string)]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Statistics Recommender Baseline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR combined MRR 0.7439168402749149, Hits@3 0.8812766939859171, Hits@1 0.5891146254184463\n"
     ]
    }
   ],
   "source": [
    "from modelextension.statistics_recommender import StatisticsRecommender as SR\n",
    "from util.metrics import calc_hits_mrr\n",
    "from util.utilities import prepare_data\n",
    "\n",
    "_, _, X_test, y_test = prepare_data(models, c_map=classes_mapping,\n",
    "                    p_map=predicates_mapping, shuffle=False, multiply=1, generate_test=True)\n",
    "\n",
    "encoded_triples = encode_triples(triples, classes_mapping, predicates_mapping)\n",
    "sr = SR(triples=encoded_triples)\n",
    "\n",
    "pred = sr.predict_links(X_test)\n",
    "hits_mrr = calc_hits_mrr( pred, y_test)\n",
    "print(f'SR {dataset} MRR {hits_mrr[\"mrr\"]}, Hits@1 {hits_mrr[\"hits@1\"]}, Hits@3 {hits_mrr[\"hits@3\"]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train RFC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "%%capture\n",
    "from util.metrics import calc_hits_mrr\n",
    "from util.utilities import prepare_data\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "\n",
    "X, y, X_test, y_test = prepare_data(vcslam_x3, c_map=classes_mapping,\n",
    "                                    p_map=predicates_mapping, shuffle=False, multiply=1, generate_test=True)\n",
    "rfc = RandomForestClassifier(n_estimators=10, max_depth=20)\n",
    "est = rfc.fit(X,y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC combined 10 20 | 0.749 0.601 0.879\n"
     ]
    }
   ],
   "source": [
    "mrrs = []\n",
    "hits_1 = []\n",
    "hits_3 = []\n",
    "pred = est.predict_proba(X_test)\n",
    "hits_mrr = calc_hits_mrr(pred, y_test)\n",
    "hits_1.append(hits_mrr['hits@1'])\n",
    "hits_3.append(hits_mrr['hits@3'])\n",
    "mrrs.append(hits_mrr['mrr'])\n",
    "\n",
    "print(f'RFC {dataset} 10 20 | {mean(mrrs):.3f} {mean(hits_1):.3f} {mean(hits_3):.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train RGCN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training triples size 173265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\repo\\semantic_recommender\\linkprediction\\utils.py:127: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  norm = 1.0 / in_deg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 MRR 0.01 hits@1 0.00 hits@3 0.00*** | epoch 200 MRR 0.02 hits@1 0.00 hits@3 0.00*** | epoch 300 MRR 0.06 hits@1 0.02 hits@3 0.02*** | epoch 400 MRR 0.09 hits@1 0.02 hits@3 0.05*** | epoch 500 MRR 0.10 hits@1 0.02 hits@3 0.07*** | epoch 600 MRR 0.33 hits@1 0.18 hits@3 0.38*** | epoch 700 MRR 0.37 hits@1 0.26 hits@3 0.39*** | epoch 800 MRR 0.37 hits@1 0.26 hits@3 0.41 | epoch 900 MRR 0.41 hits@1 0.28 hits@3 0.47*** | epoch 1000 MRR 0.67 hits@1 0.59 hits@3 0.74*** | epoch 1100 MRR 0.37 hits@1 0.24 hits@3 0.43 | epoch 1200 MRR 0.33 hits@1 0.20 hits@3 0.37 | epoch 1300 MRR 0.52 hits@1 0.39 hits@3 0.57 | epoch 1400 MRR 0.59 hits@1 0.51 hits@3 0.63 | epoch 1500 MRR 0.61 hits@1 0.54 hits@3 0.60 | epoch 1600 MRR 0.65 hits@1 0.57 hits@3 0.67 | epoch 1700 MRR 0.76 hits@1 0.68 hits@3 0.82*** | epoch 1800 MRR 0.61 hits@1 0.51 hits@3 0.70 | epoch 1900 MRR 0.61 hits@1 0.50 hits@3 0.70 | epoch 2000 MRR 0.70 hits@1 0.59 hits@3 0.78 | epoch 2100 MRR 0.74 hits@1 0.64 hits@3 0.83 | epoch 2200 MRR 0.60 hits@1 0.41 hits@3 0.78 | epoch 2300 MRR 0.71 hits@1 0.59 hits@3 0.82 | epoch 2400 MRR 0.69 hits@1 0.61 hits@3 0.72 | epoch 2500 MRR 0.67 hits@1 0.56 hits@3 0.72 | epoch 2600 MRR 0.66 hits@1 0.52 hits@3 0.81 | epoch 2700 MRR 0.73 hits@1 0.65 hits@3 0.75 | epoch 2800 MRR 0.67 hits@1 0.59 hits@3 0.71 | epoch 2900 MRR 0.72 hits@1 0.64 hits@3 0.79 | epoch 3000 MRR 0.71 hits@1 0.63 hits@3 0.73 | epoch 3100 MRR 0.57 hits@1 0.44 hits@3 0.64 | epoch 3200 MRR 0.69 hits@1 0.58 hits@3 0.80 | epoch 3300 MRR 0.79 hits@1 0.73 hits@3 0.83*** | epoch 3400 MRR 0.77 hits@1 0.69 hits@3 0.82 | epoch 3500 MRR 0.81 hits@1 0.78 hits@3 0.83*** | epoch 3600 MRR 0.71 hits@1 0.63 hits@3 0.74 | epoch 3700 MRR 0.80 hits@1 0.77 hits@3 0.82 | epoch 3800 MRR 0.79 hits@1 0.75 hits@3 0.80 | epoch 3900 MRR 0.79 hits@1 0.73 hits@3 0.83 | epoch 4000 MRR 0.61 hits@1 0.44 hits@3 0.73 | epoch 4100 MRR 0.80 hits@1 0.74 hits@3 0.84 | epoch 4200 MRR 0.82 hits@1 0.78 hits@3 0.83*** | epoch 4300 MRR 0.79 hits@1 0.72 hits@3 0.82 | epoch 4400 MRR 0.79 hits@1 0.72 hits@3 0.82 | epoch 4500 MRR 0.80 hits@1 0.76 hits@3 0.80 | epoch 4600 MRR 0.78 hits@1 0.73 hits@3 0.78 | epoch 4700 MRR 0.83 hits@1 0.80 hits@3 0.82*** | epoch 4800 MRR 0.84 hits@1 0.80 hits@3 0.84*** | epoch 4900 MRR 0.81 hits@1 0.75 hits@3 0.84 | epoch 5000 MRR 0.79 hits@1 0.73 hits@3 0.81 | epoch 5100 MRR 0.76 hits@1 0.68 hits@3 0.81 | epoch 5200 MRR 0.82 hits@1 0.78 hits@3 0.85 | epoch 5300 MRR 0.84 hits@1 0.80 hits@3 0.88 | epoch 5400 MRR 0.82 hits@1 0.78 hits@3 0.85 | epoch 5500 MRR 0.84 hits@1 0.80 hits@3 0.87 | epoch 5600 MRR 0.82 hits@1 0.74 hits@3 0.90 | epoch 5700 MRR 0.85 hits@1 0.80 hits@3 0.89*** | epoch 5800 MRR 0.84 hits@1 0.81 hits@3 0.85 | epoch 5900 MRR 0.86 hits@1 0.81 hits@3 0.89*** | epoch 6000 MRR 0.85 hits@1 0.81 hits@3 0.86 | epoch 6100 MRR 0.84 hits@1 0.80 hits@3 0.86 | epoch 6200 MRR 0.86 hits@1 0.83 hits@3 0.87 | epoch 6300 MRR 0.86 hits@1 0.81 hits@3 0.90*** | epoch 6400 MRR 0.82 hits@1 0.78 hits@3 0.84 | epoch 6500 MRR 0.86 hits@1 0.81 hits@3 0.90*** | epoch 6600 MRR 0.85 hits@1 0.78 hits@3 0.90 | epoch 6700 MRR 0.87 hits@1 0.83 hits@3 0.91*** | epoch 6800 MRR 0.84 hits@1 0.78 hits@3 0.90 | epoch 6900 MRR 0.86 hits@1 0.82 hits@3 0.90 | epoch 7000 MRR 0.86 hits@1 0.81 hits@3 0.88 | epoch 7100 MRR 0.86 hits@1 0.84 hits@3 0.88 | epoch 7200 MRR 0.84 hits@1 0.79 hits@3 0.87 | epoch 7300 MRR 0.84 hits@1 0.81 hits@3 0.86 | epoch 7400 MRR 0.86 hits@1 0.82 hits@3 0.87 | epoch 7500 MRR 0.87 hits@1 0.83 hits@3 0.88 | epoch 7600 MRR 0.85 hits@1 0.80 hits@3 0.89 | epoch 7700 MRR 0.86 hits@1 0.81 hits@3 0.88 | epoch 7800 MRR 0.79 hits@1 0.70 hits@3 0.87 | epoch 7900 MRR 0.85 hits@1 0.81 hits@3 0.86 | epoch 8000 MRR 0.87 hits@1 0.83 hits@3 0.88 | "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from linkprediction import utils\n",
    "from linkprediction.rgcn import LinkPredict, node_norm_to_edge_norm\n",
    "\n",
    "train_triples = triples\n",
    "test_triples = random.sample(triples, int(len(triples)/10))\n",
    "print(\"training triples size\", len(train_triples))\n",
    "\n",
    "train_data = encode_triples(train_triples, classes_mapping, predicates_mapping)\n",
    "valid_data = encode_triples(test_triples, classes_mapping, predicates_mapping)\n",
    "\n",
    "# load graph data\n",
    "num_nodes = len(classes)\n",
    "num_rels = len(predicates)\n",
    "\n",
    "# create model\n",
    "rgcn_model = LinkPredict(in_dim=num_nodes,\n",
    "                         h_dim=100,\n",
    "                         num_rels=num_rels,\n",
    "                         num_bases=10,\n",
    "                         num_hidden_layers=2,\n",
    "                         dropout=0.1,\n",
    "                         use_cuda=False,\n",
    "                         reg_param=0.01)\n",
    "\n",
    "# validation and testing triplets\n",
    "valid_data = torch.LongTensor(valid_data)\n",
    "test_data = torch.LongTensor(valid_data)\n",
    "\n",
    "# build test graph\n",
    "test_graph, test_rel, test_norm = utils.build_test_graph(\n",
    "    num_nodes, num_rels, train_data)\n",
    "test_deg = test_graph.in_degrees(\n",
    "    range(test_graph.number_of_nodes())).float().view(-1, 1)\n",
    "test_node_id = torch.arange(0, num_nodes, dtype=torch.long).view(-1, 1)\n",
    "test_rel = torch.from_numpy(test_rel)\n",
    "test_norm = node_norm_to_edge_norm(test_graph, torch.from_numpy(test_norm).view(-1, 1))\n",
    "\n",
    "# build adj list and calculate degrees for sampling\n",
    "adj_list, degrees = utils.get_adj_and_degrees(num_nodes, train_data)\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(rgcn_model.parameters(), lr=0.001)\n",
    "\n",
    "forward_time = []\n",
    "backward_time = []\n",
    "\n",
    "# training loop\n",
    "# print(\"start training...\")\n",
    "\n",
    "epoch = 0\n",
    "best_mrr = 0\n",
    "best_hits3 = 0\n",
    "checkpoint = None\n",
    "while True:\n",
    "    rgcn_model.train()\n",
    "    epoch += 1\n",
    "\n",
    "    # perform edge neighborhood sampling to generate training graph and data\n",
    "    g, node_id, edge_type, node_norm, data, labels = \\\n",
    "        utils.generate_sampled_graph_and_labels(\n",
    "            train_data, 20, 0.3,\n",
    "            num_rels, adj_list, degrees, 5,\n",
    "            \"neighbor\")\n",
    "    # print(\"Done edge sampling\")\n",
    "\n",
    "    # set node/edge feature\n",
    "    node_id = torch.from_numpy(node_id).view(-1, 1).long()\n",
    "    edge_type = torch.from_numpy(edge_type)\n",
    "    edge_norm = node_norm_to_edge_norm(g, torch.from_numpy(node_norm).view(-1, 1))\n",
    "    data, labels = torch.from_numpy(data), torch.from_numpy(labels)\n",
    "    deg = g.in_degrees(range(g.number_of_nodes())).float().view(-1, 1)\n",
    "\n",
    "    embed = rgcn_model(g, node_id, edge_type, edge_norm)\n",
    "    loss = rgcn_model.get_loss(g, embed, data, labels)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(rgcn_model.parameters(), 1.0)  # clip gradients\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # validation\n",
    "    if epoch % 100 == 0:\n",
    "        rgcn_model.eval()\n",
    "        # print(\"start eval\")\n",
    "        embed = rgcn_model(test_graph, test_node_id, test_rel, test_norm)\n",
    "        results = utils.calc_mrr(embed, rgcn_model.w_relation, torch.LongTensor(train_data),\n",
    "                                 valid_data, test_data, hits=[1, 3], eval_bz=100,\n",
    "                                 eval_p=\"filtered\")\n",
    "        mrr = results['mrr']\n",
    "        hits3 = results['hits@3']\n",
    "        hits1 = results['hits@1']\n",
    "        print(f\"epoch {epoch} MRR {mrr:.2f} hits@1 {hits1:.2f} hits@3 {hits3:.2f}\", end=\"\")\n",
    "        if best_hits3 < hits3:\n",
    "            best_hits3 = hits3\n",
    "        if best_mrr <= mrr:\n",
    "            best_mrr = mrr\n",
    "            checkpoint = {'state_dict': rgcn_model.state_dict(), 'epoch': epoch}\n",
    "            print(f\"*** | \", end=\"\")\n",
    "\n",
    "        else:\n",
    "            print(f\" | \", end=\"\")\n",
    "        # if hits3 == 1:\n",
    "        #    break\n",
    "\n",
    "        if epoch >= 8000:\n",
    "            break\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using best epoch: 6700\n",
      "RGCN combined MRR 0.8652116060256958 hits@1 0.8303416967391968 hits@3 0.8822867274284363\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# use best model checkpoint\n",
    "print(\"Using best epoch: {}\".format(checkpoint['epoch']))\n",
    "rgcn_model.eval()\n",
    "rgcn_model.load_state_dict(checkpoint['state_dict'])\n",
    "rgcn_embed = rgcn_model(test_graph, test_node_id, test_rel, test_norm)\n",
    "results = utils.calc_mrr(rgcn_embed, rgcn_model.w_relation, torch.LongTensor(train_data), valid_data,\n",
    "                         test_data, hits=[1, 3], eval_bz=100, eval_p=\"filtered\")\n",
    "mrr = results['mrr']\n",
    "hits3 = results['hits@3']\n",
    "hits1 = results['hits@1']\n",
    "print(f\"RGCN {dataset} MRR {mrr} hits@1 {hits1} hits@3 {hits3}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}